{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This script evaluates the performance of the custom_score evaluation\n",
      "function against a baseline agent using alpha-beta search and iterative\n",
      "deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use\n",
      "ID and alpha-beta search with the custom_score functions defined in\n",
      "game_agent.py.\n",
      "\n",
      "                        *************************                         \n",
      "                             Playing Matches                              \n",
      "                        *************************                         \n",
      "\n",
      " Match #   Opponent    AB_Improved   AB_Custom   AB_Custom_2  AB_Custom_3 \n",
      "                        Won | Lost   Won | Lost   Won | Lost   Won | Lost \n",
      "    1       Random    "
     ]
    }
   ],
   "source": [
    "\"\"\"Estimate the strength rating of a student defined heuristic by competing\n",
    "against fixed-depth minimax and alpha-beta search agents in a round-robin\n",
    "tournament.\n",
    "\n",
    "NOTE: All agents are constructed from the student CustomPlayer implementation,\n",
    "so any errors present in that class will affect the outcome.\n",
    "\n",
    "The student agent plays a number of \"fair\" matches against each test agent.\n",
    "The matches are fair because the board is initialized randomly for both\n",
    "players, and the players play each match twice -- once as the first player and\n",
    "once as the second player.  Randomizing the openings and switching the player\n",
    "order corrects for imbalances due to both starting position and initiative.\n",
    "\"\"\"\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from isolation import Board\n",
    "from sample_players import (RandomPlayer, open_move_score,\n",
    "                            improved_score, center_score)\n",
    "from game_agent import (MinimaxPlayer, AlphaBetaPlayer, custom_score,\n",
    "                        custom_score_2, custom_score_3)\n",
    "\n",
    "NUM_MATCHES = 5  # number of matches against each opponent\n",
    "TIME_LIMIT = 150  # number of milliseconds before timeout\n",
    "\n",
    "DESCRIPTION = \"\"\"\n",
    "This script evaluates the performance of the custom_score evaluation\n",
    "function against a baseline agent using alpha-beta search and iterative\n",
    "deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use\n",
    "ID and alpha-beta search with the custom_score functions defined in\n",
    "game_agent.py.\n",
    "\"\"\"\n",
    "\n",
    "Agent = namedtuple(\"Agent\", [\"player\", \"name\"])\n",
    "\n",
    "\n",
    "def play_round(cpu_agent, test_agents, win_counts, num_matches):\n",
    "    \"\"\"Compare the test agents to the cpu agent in \"fair\" matches.\n",
    "\n",
    "    \"Fair\" matches use random starting locations and force the agents to\n",
    "    play as both first and second player to control for advantages resulting\n",
    "    from choosing better opening moves or having first initiative to move.\n",
    "    \"\"\"\n",
    "    timeout_count = 0\n",
    "    forfeit_count = 0\n",
    "    for _ in range(num_matches):\n",
    "\n",
    "        games = sum([[Board(cpu_agent.player, agent.player),\n",
    "                      Board(agent.player, cpu_agent.player)]\n",
    "                    for agent in test_agents], [])\n",
    "\n",
    "        # initialize all games with a random move and response\n",
    "        for _ in range(2):\n",
    "            move = random.choice(games[0].get_legal_moves())\n",
    "            for game in games:\n",
    "                game.apply_move(move)\n",
    "\n",
    "        # play all games and tally the results\n",
    "        for game in games:\n",
    "            winner, _, termination = game.play(time_limit=TIME_LIMIT)\n",
    "            win_counts[winner] += 1\n",
    "\n",
    "            if termination == \"timeout\":\n",
    "                timeout_count += 1\n",
    "            elif termination == \"forfeit\":\n",
    "                forfeit_count += 1\n",
    "\n",
    "    return timeout_count, forfeit_count\n",
    "\n",
    "\n",
    "def update(total_wins, wins):\n",
    "    for player in total_wins:\n",
    "        total_wins[player] += wins[player]\n",
    "    return total_wins\n",
    "\n",
    "\n",
    "def play_matches(cpu_agents, test_agents, num_matches):\n",
    "    \"\"\"Play matches between the test agent and each cpu_agent individually. \"\"\"\n",
    "    total_wins = {agent.player: 0 for agent in test_agents}\n",
    "    total_timeouts = 0.\n",
    "    total_forfeits = 0.\n",
    "    total_matches = 2 * num_matches * len(cpu_agents)\n",
    "\n",
    "    print(\"\\n{:^9}{:^13}\".format(\"Match #\", \"Opponent\") + ''.join(['{:^13}'.format(x[1].name) for x in enumerate(test_agents)]))\n",
    "    print(\"{:^9}{:^13} \".format(\"\", \"\") +  ' '.join(['{:^5}| {:^5}'.format(\"Won\", \"Lost\") for x in enumerate(test_agents)]))\n",
    "\n",
    "    for idx, agent in enumerate(cpu_agents):\n",
    "        wins = {key: 0 for (key, value) in test_agents}\n",
    "        wins[agent.player] = 0\n",
    "\n",
    "        print(\"{!s:^9}{:^13}\".format(idx + 1, agent.name), end=\"\", flush=True)\n",
    "\n",
    "        counts = play_round(agent, test_agents, wins, num_matches)\n",
    "        total_timeouts += counts[0]\n",
    "        total_forfeits += counts[1]\n",
    "        total_wins = update(total_wins, wins)\n",
    "        _total = 2 * num_matches\n",
    "        round_totals = sum([[wins[agent.player], _total - wins[agent.player]]\n",
    "                            for agent in test_agents], [])\n",
    "        print(' ' + ' '.join([\n",
    "            '{:^5}| {:^5}'.format(\n",
    "                round_totals[i],round_totals[i+1]\n",
    "            ) for i in range(0, len(round_totals), 2)\n",
    "        ]))\n",
    "\n",
    "    print(\"-\" * 74)\n",
    "    print('{:^9}{:^13}'.format(\"\", \"Win Rate:\") +\n",
    "        ''.join([\n",
    "            '{:^13}'.format(\n",
    "                \"{:.1f}%\".format(100 * total_wins[x[1].player] / total_matches)\n",
    "            ) for x in enumerate(test_agents)\n",
    "    ]))\n",
    "\n",
    "    if total_timeouts:\n",
    "        print((\"\\nThere were {} timeouts during the tournament -- make sure \" +\n",
    "               \"your agent handles search timeout correctly, and consider \" +\n",
    "               \"increasing the timeout margin for your agent.\\n\").format(\n",
    "            total_timeouts))\n",
    "    if total_forfeits:\n",
    "        print((\"\\nYour ID search forfeited {} games while there were still \" +\n",
    "               \"legal moves available to play.\\n\").format(total_forfeits))\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Define two agents to compare -- these agents will play from the same\n",
    "    # starting position against the same adversaries in the tournament\n",
    "    test_agents = [\n",
    "        Agent(AlphaBetaPlayer(score_fn=improved_score), \"AB_Improved\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=custom_score), \"AB_Custom\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=custom_score_2), \"AB_Custom_2\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=custom_score_3), \"AB_Custom_3\")\n",
    "    ]\n",
    "\n",
    "    # Define a collection of agents to compete against the test agents\n",
    "    cpu_agents = [\n",
    "        Agent(RandomPlayer(), \"Random\"),\n",
    "        Agent(MinimaxPlayer(score_fn=open_move_score), \"MM_Open\"),\n",
    "        Agent(MinimaxPlayer(score_fn=center_score), \"MM_Center\"),\n",
    "        Agent(MinimaxPlayer(score_fn=improved_score), \"MM_Improved\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=open_move_score), \"AB_Open\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=center_score), \"AB_Center\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=improved_score), \"AB_Improved\")\n",
    "    ]\n",
    "\n",
    "    print(DESCRIPTION)\n",
    "    print(\"{:^74}\".format(\"*************************\"))\n",
    "    print(\"{:^74}\".format(\"Playing Matches\"))\n",
    "    print(\"{:^74}\".format(\"*************************\"))\n",
    "    play_matches(cpu_agents, test_agents, NUM_MATCHES)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
